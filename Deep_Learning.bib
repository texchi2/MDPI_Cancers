Automatically generated by Mendeley Desktop 1.19.4
Any changes to this file will be lost if it is regenerated by Mendeley.

BibTeX export options can be customized via Preferences -> BibTeX in Mendeley Desktop

@misc{Grattarola2020,
abstract = {In this paper we present Spektral, an open-source Python library for building graph neural networks with TensorFlow and the Keras application programming interface. Spektral implements a large set of methods for deep learning on graphs, including message-passing and pooling operators, as well as utilities for processing graphs and loading popular benchmark datasets. The purpose of this library is to provide the essential building blocks for creating graph neural networks, focusing on the guiding principles of user-friendliness and quick prototyping on which Keras is based. Spektral is, therefore, suitable for absolute beginners and expert deep learning practitioners alike. In this work, we present an overview of Spektral's features and report the performance of the methods implemented by the library in scenarios of node classification, graph classification, and graph regression.},
archivePrefix = {arXiv},
arxivId = {cs.LG/2006.12138},
author = {Grattarola, Daniele and Alippi, Cesare},
eprint = {2006.12138},
keywords = {GNN,keras,tensorflow},
mendeley-tags = {GNN,keras,tensorflow},
primaryClass = {cs.LG},
title = {{Graph Neural Networks in TensorFlow and Keras with Spektral}},
url = {https://github.com/danielegrattarola/spektral},
year = {2020}
}
@article{Wang2020,
abstract = {BACKGROUND AND OBJECTIVE: Cancer, as the most challenging part in the human disease history, has always been one of the main threats to human life and health. The high mortality of cancer is largely due to the complexity of cancer and the significant differences in clinical outcomes. Therefore, it will be significant to improve accuracy of cancer survival prediction, which has become one of the main fields of cancer research. Many calculation models for cancer survival prediction have been proposed at present, but most of them generate prediction models only by using single genomic data or clinical data. Multiple genomic data and clinical data have not been integrated yet to take a comprehensive consideration of cancers and predict their survival. METHOD: In order to effectively integrate multiple genomic data (including genetic expression, copy number alteration, DNA methylation and exon expression) and clinical data and apply them to predictive studies on cancer survival, similar network fusion algorithm (SNF) was proposed in this paper to integrate multiple genomic data and clinical data so as to generate sample similarity matrix, min-redundancy and max-relevance algorithm (mRMR) was used to conduct feature selection of multiple genomic data and clinical data of cancer samples and generate sample feature matrix, and finally two matrixes were used for semi-supervised training through graph convolutional network (GCN) so as to obtain a cancer survival prediction method integrating multiple genomic data and clinical data based on graph convolutional network (GCGCN). RESULT: Performance indexes of GCGCN model indicate that both multiple genomic data and clinical data play significant roles in the accurate survival time prediction of cancer patients. It is compared with existing survival prediction methods, and results show that cancer survival prediction method GCGCN which integrates multiple genomic data and clinical data has obviously superior prediction effect than existing survival prediction methods. CONCLUSION: All study results in this paper have verified effectiveness and superiority of GCGCN in the aspect of cancer survival prediction.},
author = {Wang, Chunyu and Guo, Junling and Zhao, Ning and Liu, Yang and Liu, Xiaoyan and Liu, Guojun and Guo, Maozu},
doi = {10.1109/TNB.2019.2936398},
file = {:Users/texchi/Downloads/wang2019.pdf:pdf},
issn = {1558-2639 (Electronic)},
journal = {IEEE transactions on nanobioscience},
keywords = {Algorithms,CNN,Computer,GCGCN,GCN,Genomics,Humans,Models,Neoplasms,Neural Networks,Prognosis,Statistical,Survival Analysis,diagnosis,genetics,graph,methods,mortality,survival},
language = {eng},
mendeley-tags = {CNN,GCGCN,GCN,graph,survival},
month = {jan},
number = {1},
pages = {117--126},
pmid = {31443039},
title = {{A Cancer Survival Prediction Method Based on Graph Convolutional Network}},
url = {https://ieeexplore.ieee.org/document/8809103/figures{\#}figures},
volume = {19},
year = {2020}
}
@article{MoradiFard2020,
abstract = {We study in this paper the problem of jointly clustering and learning representations. As several previous studies have shown, learning representations that are both faithful to the data to be clustered and adapted to the clustering algorithm can lead to better clustering performance, all the more so that the two tasks are performed jointly. We propose here such an approach for k-Means clustering based on a continuous reparametrization of the objective function that leads to a truly joint solution. The behavior of our approach is illustrated on various datasets showing its efficacy in learning representations for objects while clustering them.},
author = {{Moradi Fard}, Maziar and Thonet, Thibaut and Gaussier, Eric},
doi = {https://doi.org/10.1016/j.patrec.2020.07.028},
file = {:Users/texchi/Downloads/1-s2.0-S0167865520302749-main.pdf:pdf},
issn = {0167-8655},
journal = {Pattern Recognition Letters},
keywords = {Clustering,Deep clustering,Deep learning,deep clustering; k-Means; deep learning; clustering,k-Means},
mendeley-tags = {deep clustering; k-Means; deep learning; clustering},
pages = {185--192},
title = {{Deep k-Means: Jointly clustering with k-Means and learning representations}},
url = {http://www.sciencedirect.com/science/article/pii/S0167865520302749},
volume = {138},
year = {2020}
}
@article{Ren2019,
abstract = {Survival analysis is a hotspot in statistical research for modeling time-to-event information with data censorship handling, which has been widely used in many applications such as clinical research, information system and other fields with survivorship bias. Many works have been proposed for survival analysis ranging from traditional statistic methods to machine learning models. However, the existing methodologies either utilize counting-based statistics on the segmented data, or have a pre-assumption on the event probability distribution w.r.t. time. Moreover, few works consider sequential patterns within the feature space. In this paper, we propose a Deep Recurrent Survival Analysis model which combines deep learning for conditional probability prediction at finegrained level of the data, and survival analysis for tackling the censorship. By capturing the time dependency through modeling the conditional probability of the event for each sample, our method predicts the likelihood of the true event occurrence and estimates the survival rate over time, i.e., the probability of the non-occurrence of the event, for the censored data. Meanwhile, without assuming any specific form of the event probability distribution, our model shows great advantages over the previous works on fitting various sophisticated data distributions. In the experiments on the three realworld tasks from different fields, our model significantly outperforms the state-of-the-art solutions under various metrics.},
archivePrefix = {arXiv},
arxivId = {1809.02403},
author = {Ren, Kan and Qin, Jiarui and Zheng, Lei and Yang, Zhengyu and Zhang, Weinan and Qiu, Lin and Yu, Yong},
doi = {10.1609/aaai.v33i01.33014798},
eprint = {1809.02403},
file = {:Users/texchi/Downloads/4407-Article Text-7446-1-10-20190706.pdf:pdf},
isbn = {9781577358091},
issn = {2374-3468},
journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
keywords = {L2L,NAS,RNN,architecture search,censoring,deep learning,evolution,evolutionary algorithms,genetic algorithms,image classification,learning to learn,learning-to-learn,meta learning,meta-learning,neural networks,neuro-evolution,neuroevolution,reinforcement,reinforcement learning,rl},
mendeley-tags = {RNN,censoring,deep learning},
month = {jul},
pages = {4798--4805},
title = {{Deep Recurrent Survival Analysis}},
url = {https://aaai.org/ojs/index.php/AAAI/article/view/4407},
volume = {33},
year = {2019}
}
@inproceedings{Giunchiglia2018,
abstract = {Current medical practice is driven by clinical guidelines which are designed for the “average” patient. Deep learning is enabling medicine to become personalized to the patient at hand. In this paper we present a new recurrent neural network model for personalized survival analysis called rnn-surv. Our model is able to exploit censored data to compute both the risk score and the survival function of each patient. At each time step, the network takes as input the features characterizing the patient and the identifier of the time step, creates an embedding, and outputs the value of the survival function in that time step. Finally, the values of the survival function are linearly combined to compute the unique risk score. Thanks to the model structure and the training designed to exploit two loss functions, our model gets better concordance index (C-index) than the state of the art approaches.},
author = {Giunchiglia, Eleonora and Nemchenko, Anton and van der Schaar, Mihaela},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-030-01424-7_3},
file = {:Users/texchi/Downloads/RNN{\_}SURV.pdf:pdf},
isbn = {9783030014230},
issn = {16113349},
keywords = {RNN-SURV},
mendeley-tags = {RNN-SURV},
pages = {23--32},
title = {{RNN-SURV: A Deep Recurrent Model for Survival Analysis BT - Artificial Neural Networks and Machine Learning – ICANN 2018}},
year = {2018}
}
@article{Lai2020,
abstract = {Non-small cell lung cancer (NSCLC) is one of the most common lung cancers worldwide. Accurate prognostic stratification of NSCLC can become an important clinical reference when designing therapeutic strategies for cancer patients. With this clinical application in mind, we developed a deep neural network (DNN) combining heterogeneous data sources of gene expression and clinical data to accurately predict the overall survival of NSCLC patients. Based on microarray data from a cohort set (614 patients), seven well-known NSCLC biomarkers were used to group patients into biomarker- and biomarker+ subgroups. Then, by using a systems biology approach, prognosis relevance values (PRV) were then calculated to select eight additional novel prognostic gene biomarkers. Finally, the combined 15 biomarkers along with clinical data were then used to develop an integrative DNN via bimodal learning to predict the 5-year survival status of NSCLC patients with tremendously high accuracy (AUC: 0.8163, accuracy: 75.44{\%}). Using the capability of deep learning, we believe that our prediction can be a promising index that helps oncologists and physicians develop personalized therapy and build the foundation of precision medicine in the future.},
annote = {https://github.com/idssplab/overall{\_}survival{\_}nsclc},
author = {Lai, Yu-Heng and Chen, Wei-Ning and Hsu, Te-Cheng and Lin, Che and Tsao, Yu and Wu, Semon},
doi = {10.1038/s41598-020-61588-w},
issn = {2045-2322 (Electronic)},
journal = {Scientific reports},
keywords = {Area Under Curve,Biomarkers,Carcinoma,Computational Biology,Deep Learning,Humans,Kaplan-Meier Estimate,Lung Neoplasms,Microarray Analysis,Neoplasm Grading,Neoplasm Metastasis,Neoplasm Staging,Non-Small-Cell Lung,Reproducibility of Results,Support Vector Machine,Tumor,Workflow,diagnosis,etiology,methods,mortality},
language = {eng},
month = {mar},
number = {1},
pages = {4679},
pmid = {32170141},
title = {{Overall survival prediction of non-small cell lung cancer by integrating microarray and clinical data with deep learning.}},
url = {https://www.nature.com/articles/s41598-020-61588-w},
volume = {10},
year = {2020}
}
@article{Liu2020,
abstract = {Electronic health records (EHRs) have been widely used to help physicians to make decisions by predicting medical events such as diseases, prescriptions, outcomes, and so on. How to represent patient longitudinal medical data is the key to making these predictions. Recurrent neural network (RNN) is a popular model for patient longitudinal medical data representation from the view of patient status sequences, but it cannot represent complex interactions among different types of medical information, i.e., temporal medical event graphs, which can be represented by graph neural network (GNN). In this paper, we propose a hybrid method of RNN and GNN, called RGNN, for next-period prescription prediction from two views, where RNN is used to represent patient status sequences, and GNN is used to represent temporal medical event graphs. Experiments conducted on the public MIMIC-III ICU data show that the proposed method is effective for next-period prescription prediction, and RNN and GNN are mutually complementary.},
annote = {Graph neural network (GNN) is a kind of deep neural network powerful for complex graphs [23]. Several methods are recently proposed to compute representations of nodes, edges, and graphs [24,25,26]. Among them, Graph Convolutional Network (GCN) that computes the representation of a node recursively from its neighbors is the most common one [27] and is widely applied to many domains such as natural language processing and knowledge graph representation. In the medical domain, GCN starts to be applied to many tasks. For example, Choi et al.'s deployed GCN to learn medical concept representations from the graph of medical ontology knowledge [28]. Ma et al.'s recognized the drug–drug interaction (DDI) problem as a graph classification problem and solve it by GCN [29]. Besides GCN, some other GNNs also have been proposed recently such as GAMENet [30] and Decagon [31]. GAMENet is a Graph Augmented Memory Network designed to integrate the DDI knowledge graph for the personalized recommendation of medication combination. Decagon is a multi-modal GNN for drug side effect prediction.

={\textgreater} Decagon
Zitnik M, Agrawal M, Leskovec J (2018) Modeling polypharmacy side effects with graph convolutional networks. Bioinformatics 34:i457–i466. https://doi.org/10.1093/bioinformatics/bty294},
author = {Liu, Sicen and Li, Tao and Ding, Haoyang and Tang, Buzhou and Wang, Xiaolong and Chen, Qingcai and Yan, Jun and Zhou, Yi},
doi = {10.1007/s13042-020-01155-x},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Liu et al. - 2020 - A hybrid method of recurrent neural network and graph neural network for next-period prescription prediction.pdf:pdf},
issn = {1868-808X},
journal = {International Journal of Machine Learning and Cybernetics},
keywords = {GNN},
mendeley-tags = {GNN},
number = {12},
pages = {2849--2856},
title = {{A hybrid method of recurrent neural network and graph neural network for next-period prescription prediction}},
url = {https://doi.org/10.1007/s13042-020-01155-x},
volume = {11},
year = {2020}
}
@inproceedings{Gao2020a,
abstract = {Predicting the survival of cancer patients holds significant meaning for public health, and has attracted increasing attention in medical information communities. In this study, we propose a novel framework for cancer survival prediction named Multimodal Graph Neural Network (MGNN), which explores the features of real-world multimodual data such as gene expression, copy number alteration and clinical data in a unified framework. In order to explore the inherent relation, we first construct the bipartite graphs between patients and multimodal data. Subsequently, graph neural network is adopted to obtain the embedding of each patient on different bipartite graphs. Finally, a multimodal fusion neural layer is designed to fuse the features from different modal data. The output of our method is the classification of short term survival or long term survival for each patient. Experimental results on one breast cancer dataset demonstrate that MGNN outperforms all baselines. Furthermore, we test the trained model on lung cancer dataset, and the experimental results verify the strong robust by comparing with state-of-the-art methods.},
address = {New York, NY, USA},
annote = {From Duplicate 1 (MGNN: A Multimodal Graph Neural Network for Predicting the Survival of Cancer Patients - Gao, Jianliang; Lyu, Tengfei; Xiong, Fan; Wang, Jianxin; Ke, Weimao; Li, Zhao)

$\backslash$citep{\{}Kim2019{\}} using DeepSurv in HNSCC
=

MDNNMD
[6] Dongdong Sun, Minghui Wang, and A o Li. 
A Multimodal Deep Neural Network for Human Breast Cancer Prognosis Prediction by Integrating Multi-Dimensional Data. TCBB, 16(3):841-850, 2018.

MDNNMD
=={\textgreater} 1. Sun, D., Wang, M. {\&} Li, A. A Multimodal Deep Neural Network for Human Breast Cancer Prognosis Prediction by Integrating Multi-Dimensional Data. IEEE/ACM Trans. Comput. Biol. Bioinforma. 16, 841–850 (2019). $\backslash$citep{\{}Sun2019{\}}},
author = {Gao, Jianliang and Lyu, Tengfei and Xiong, Fan and Wang, Jianxin and Ke, Weimao and Li, Zhao},
booktitle = {SIGIR 2020 - Proceedings of the 43rd International ACM SIGIR Conference on Research and Development in Information Retrieval},
doi = {10.1145/3397271.3401214},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Gao et al. - 2020 - MGNN A Multimodal Graph Neural Network for Predicting the Survival of Cancer Patients(2).pdf:pdf;:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Gao et al. - 2020 - MGNN A Multimodal Graph Neural Network for Predicting the Survival of Cancer Patients.docx:docx},
isbn = {9781450380164},
keywords = {cancer survival prediction,deep learning,graph neural networks,medical information retrieval,multimodal,survival},
mendeley-tags = {deep learning,survival},
month = {jul},
pages = {1697--1700},
publisher = {Association for Computing Machinery, Inc},
series = {SIGIR '20},
title = {{MGNN: A Multimodal Graph Neural Network for Predicting the Survival of Cancer Patients}},
url = {https://doi.org/10.1145/3397271.3401214 https://www.semanticscholar.org/paper/MGNN{\%}3A-A-Multimodal-Graph-Neural-Network-for-the-of-Gao-Lyu/acf3332e8ae664238f8cf18f903e004a390a271e/figure/0},
year = {2020}
}
@article{Fu2020,
abstract = {This is an editorial report of the supplements to BMC Bioinformatics that includes 6 papers selected from the BIOCOMP'19—The 2019 International Conference on Bioinformatics and Computational Biology. These articles reflect current trend and development in bioinformatics research.},
author = {Fu, Yuanyuan and Ling, Zhougui and Arabnia, Hamid and Deng, Youping},
doi = {10.1186/s12859-020-03874-y},
file = {:Users/texchi/Downloads/s12859-020-03874-y.pdf:pdf},
issn = {1471-2105},
journal = {BMC Bioinformatics},
number = {9},
pages = {538},
title = {{Current trend and development in bioinformatics research}},
url = {https://doi.org/10.1186/s12859-020-03874-y},
volume = {21},
year = {2020}
}
@article{Li2019a,
abstract = {Deep learning, which is especially formidable in handling big data, has achieved great success in various fields, including bioinformatics. With the advances of the big data era in biology, it is foreseeable that deep learning will become increasingly important in the field and will be incorporated in vast majorities of analysis pipelines. In this review, we provide both the exoteric introduction of deep learning, and concrete examples and implementations of its representative applications in bioinformatics. We start from the recent achievements of deep learning in the bioinformatics field, pointing out the problems which are suitable to use deep learning. After that, we introduce deep learning in an easy-to-understand fashion, from shallow neural networks to legendary convolutional neural networks, legendary recurrent neural networks, graph neural networks, generative adversarial networks, variational autoencoder, and the most recent state-of-the-art architectures. After that, we provide eight examples, covering five bioinformatics research directions and all the four kinds of data type, with the implementation written in Tensorflow and Keras. Finally, we discuss the common issues, such as overfitting and interpretability, that users will encounter when adopting deep learning methods and provide corresponding suggestions. The implementations are freely available at https://github.com/lykaust15/Deep{\_}learning{\_}examples.},
author = {Li, Yu and Huang, Chao and Ding, Lizhong and Li, Zhongxiao and Pan, Yijie and Gao, Xin},
doi = {https://doi.org/10.1016/j.ymeth.2019.04.008},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Li et al. - 2019 - Deep learning in bioinformatics Introduction, application, and perspective in the big data era.pdf:pdf;:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Li et al. - 2019 - Deep learning in bioinformatics Introduction, application, and perspective in the big data era.docx:docx},
issn = {1046-2023},
journal = {Methods},
pages = {4--21},
title = {{Deep learning in bioinformatics: Introduction, application, and perspective in the big data era}},
url = {http://www.sciencedirect.com/science/article/pii/S1046202318303256},
volume = {166},
year = {2019}
}
@article{Hao2020,
abstract = {The integration of multi-modal data, such as histopathological images and genomic data, is essential for understanding cancer heterogeneity and complexity for personalized treatments, as well as for enhancing survival predictions in cancer study. Histopathology, as a clinical gold-standard tool for diagnosis and prognosis in cancers, allows clinicians to make precise decisions on therapies, whereas high-throughput genomic data have been investigated to dissect the genetic mechanisms of cancers. We propose a biologically interpretable deep learning model (PAGE-Net) that integrates histopathological images and genomic data, not only to improve survival prediction, but also to identify genetic and histopathological patterns that cause different survival rates in patients. PAGE-Net consists of pathology/genome/demography-specific layers, each of which provides comprehensive biological interpretation. In particular, we propose a novel patch-wise texture-based convolutional neural network, with a patch aggregation strategy, to extract global survival-discriminative features, without manual annotation for the pathology-specific layers. We adapted the pathway-based sparse deep neural network, named Cox-PASNet, for the genome-specific layers. The proposed deep learning model was assessed with the histopathological images and the gene expression data of Glioblastoma Multiforme (GBM) at The Cancer Genome Atlas (TCGA) and The Cancer Imaging Archive (TCIA). PAGE-Net achieved a C-index of 0.702, which is higher than the results achieved with only histopathological images (0.509) and Cox-PASNet (0.640). More importantly, PAGE-Net can simultaneously identify histopathological and genomic prognostic factors associated with patients survivals. The source code of PAGE-Net is publicly available at https://github.com/DataX-JieHao/PAGE-Net.},
annote = {https://github.com/DataX-JieHao/PAGE-Net

The proposed deep learning model was assessed with the histopathological images and the gene expression data of Glioblastoma Multiforme (GBM) at The Cancer Genome Atlas (TCGA) and The Cancer Imaging Archive (TCIA). PAGE-Net achieved a C-index of 0.702, which is higher than the results achieved with only histopathological images (0.509) and Cox-PASNet (0.640)},
author = {Hao, Jie and Kosaraju, Sai Chandra and Tsaku, Nelson Zange and Song, Dae Hyun and Kang, Mingon},
file = {:Users/texchi/Downloads/9789811215636{\_}0032.pdf:pdf},
issn = {2335-6936 (Electronic)},
journal = {Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing},
language = {eng},
pages = {355--366},
pmid = {31797610},
title = {{PAGE-Net: Interpretable and Integrative Deep Learning for Survival Analysis Using Histopathological Images and Genomic Data.}},
volume = {25},
year = {2020}
}
@inproceedings{Giunchiglia2018a,
abstract = {Current medical practice is driven by clinical guidelines which are designed for the “average” patient. Deep learning is enabling medicine to become personalized to the patient at hand. In this paper we present a new recurrent neural network model for personalized survival analysis called rnn-surv. Our model is able to exploit censored data to compute both the risk score and the survival function of each patient. At each time step, the network takes as input the features characterizing the patient and the identifier of the time step, creates an embedding, and outputs the value of the survival function in that time step. Finally, the values of the survival function are linearly combined to compute the unique risk score. Thanks to the model structure and the training designed to exploit two loss functions, our model gets better concordance index (C-index) than the state of the art approaches.},
address = {Cham},
annote = {https://github.com/data-modeler/rnn-surv},
author = {Giunchiglia, Eleonora and Nemchenko, Anton and van der Schaar, Mihaela},
editor = {Kůrkov{\'{a}}, V{\v{e}}ra and Manolopoulos, Yannis and Hammer, Barbara and Iliadis, Lazaros and Maglogiannis, Ilias},
file = {:Users/texchi/Downloads/RNN{\_}SURV.pdf:pdf},
isbn = {978-3-030-01424-7},
keywords = {RNN-SURV,censoring},
mendeley-tags = {RNN-SURV,censoring},
pages = {23--32},
publisher = {Springer International Publishing},
title = {{RNN-SURV: A Deep Recurrent Model for Survival Analysis BT - Artificial Neural Networks and Machine Learning – ICANN 2018}},
url = {https://link.springer.com/chapter/10.1007/978-3-030-01424-7{\_}3},
year = {2018}
}
@article{Ren2019a,
abstract = {{\textless}p{\textgreater}Survival analysis is a hotspot in statistical research for modeling time-to-event information with data censorship handling, which has been widely used in many applications such as clinical research, information system and other fields with survivorship bias. Many works have been proposed for survival analysis ranging from traditional statistic methods to machine learning models. However, the existing methodologies either utilize counting-based statistics on the segmented data, or have a pre-assumption on the event probability distribution w.r.t. time. Moreover, few works consider sequential patterns within the feature space. In this paper, we propose a Deep Recurrent Survival Analysis model which combines deep learning for conditional probability prediction at finegrained level of the data, and survival analysis for tackling the censorship. By capturing the time dependency through modeling the conditional probability of the event for each sample, our method predicts the likelihood of the true event occurrence and estimates the survival rate over time, i.e., the probability of the {\textless}em{\textgreater}non{\textless}/em{\textgreater}-occurrence of the event, for the censored data. Meanwhile, without assuming any specific form of the event probability distribution, our model shows great advantages over the previous works on fitting various sophisticated data distributions. In the experiments on the three realworld tasks from different fields, our model significantly outperforms the state-of-the-art solutions under various metrics.{\textless}/p{\textgreater}},
author = {Ren, Kan and Qin, Jiarui and Zheng, Lei and Yang, Zhengyu and Zhang, Weinan and Qiu, Lin and Yu, Yong},
doi = {10.1609/aaai.v33i01.33014798},
journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
month = {jul},
number = {01 SE  - AAAI Technical Track: Machine Learning},
pages = {4798--4805},
title = {{Deep Recurrent Survival Analysis}},
url = {https://ojs.aaai.org/index.php/AAAI/article/view/4407},
volume = {33},
year = {2019}
}
@article{Hao2019,
abstract = {BACKGROUND: Understanding the complex biological mechanisms of cancer patient survival using genomic and clinical data is vital, not only to develop new treatments for patients, but also to improve survival prediction. However, highly nonlinear and high-dimension, low-sample size (HDLSS) data cause computational challenges to applying conventional survival analysis. RESULTS: We propose a novel biologically interpretable pathway-based sparse deep neural network, named Cox-PASNet, which integrates high-dimensional gene expression data and clinical data on a simple neural network architecture for survival analysis. Cox-PASNet is biologically interpretable where nodes in the neural network correspond to biological genes and pathways, while capturing the nonlinear and hierarchical effects of biological pathways associated with cancer patient survival. We also propose a heuristic optimization solution to train Cox-PASNet with HDLSS data. Cox-PASNet was intensively evaluated by comparing the predictive performance of current state-of-the-art methods on glioblastoma multiforme (GBM) and ovarian serous cystadenocarcinoma (OV) cancer. In the experiments, Cox-PASNet showed out-performance, compared to the benchmarking methods. Moreover, the neural network architecture of Cox-PASNet was biologically interpreted, and several significant prognostic factors of genes and biological pathways were identified. CONCLUSIONS: Cox-PASNet models biological mechanisms in the neural network by incorporating biological pathway databases and sparse coding. The neural network of Cox-PASNet can identify nonlinear and hierarchical associations of genomic and clinical data to cancer patient survival. The open-source code of Cox-PASNet in PyTorch implemented for training, evaluation, and model interpretation is available at: https://github.com/DataX-JieHao/Cox-PASNet.},
annote = {https://github.com/DataX-JieHao/Cox-PASNet

highly nonlinear and high-dimension, low-sample size (HDLSS) data cause computational challenges to applying conventional survival analysis.

Selected articles from the IEEE BIBM International Conference on Bioinformatics {\&} Biomedicine (BIBM) 2018: medical genomics},
author = {Hao, Jie and Kim, Youngsoon and Mallavarapu, Tejaswini and Oh, Jung Hun and Kang, Mingon},
doi = {10.1186/s12920-019-0624-2},
file = {:Users/texchi/Downloads/s12920-019-0624-2.pdf:pdf},
issn = {1755-8794 (Electronic)},
journal = {BMC medical genomics},
keywords = {Computational Biology,Cox proportional hazards analyses,Cox-PASNet,Deep Learning,Humans,Neoplasms,Proportional Hazards Models,deep learning,genetics,methods,survival},
language = {eng},
mendeley-tags = {Cox proportional hazards analyses,Cox-PASNet,deep learning,survival},
month = {dec},
number = {Suppl 10},
pages = {189},
pmid = {31865908},
title = {{Interpretable deep neural network for cancer survival analysis by integrating genomic and clinical data.}},
url = {https://bmcmedgenomics.biomedcentral.com/articles/10.1186/s12920-019-0624-2},
volume = {12},
year = {2019}
}
@article{Ren2019,
abstract = {Survival analysis is a hotspot in statistical research for modeling time-to-event information with data censorship handling, which has been widely used in many applications such as clinical research, information system and other fields with survivorship bias. Many works have been proposed for survival analysis ranging from traditional statistic methods to machine learning models. However, the existing methodologies either utilize counting-based statistics on the segmented data, or have a pre-assumption on the event probability distribution w.r.t. time. Moreover, few works consider sequential patterns within the feature space. In this paper, we propose a Deep Recurrent Survival Analysis model which combines deep learning for conditional probability prediction at finegrained level of the data, and survival analysis for tackling the censorship. By capturing the time dependency through modeling the conditional probability of the event for each sample, our method predicts the likelihood of the true event occurrence and estimates the survival rate over time, i.e., the probability of the non-occurrence of the event, for the censored data. Meanwhile, without assuming any specific form of the event probability distribution, our model shows great advantages over the previous works on fitting various sophisticated data distributions. In the experiments on the three realworld tasks from different fields, our model significantly outperforms the state-of-the-art solutions under various metrics.},
archivePrefix = {arXiv},
arxivId = {1809.02403},
author = {Ren, Kan and Qin, Jiarui and Zheng, Lei and Yang, Zhengyu and Zhang, Weinan and Qiu, Lin and Yu, Yong},
doi = {10.1609/aaai.v33i01.33014798},
eprint = {1809.02403},
file = {:Users/texchi/Downloads/4407-Article Text-7446-1-10-20190706.pdf:pdf},
isbn = {9781577358091},
issn = {2374-3468},
journal = {Proceedings of the AAAI Conference on Artificial Intelligence},
keywords = {L2L,NAS,RNN,architecture search,censoring,deep learning,evolution,evolutionary algorithms,genetic algorithms,image classification,learning to learn,learning-to-learn,meta learning,meta-learning,neural networks,neuro-evolution,neuroevolution,reinforcement,reinforcement learning,rl},
mendeley-tags = {RNN,censoring,deep learning},
month = {jul},
number = {01 SE - AAAI Technical Track: Machine Learning},
pages = {4798--4805},
title = {{Deep Recurrent Survival Analysis}},
url = {https://ojs.aaai.org/index.php/AAAI/article/view/4407 https://aaai.org/ojs/index.php/AAAI/article/view/4407},
volume = {33},
year = {2019}
}
@article{Bhinder2020,
abstract = {The remarkable success of cancer immunotherapies, especially the checkpoint blocking antibodies, in a subset of patients has reinvigorated the study of tumor-immune crosstalk and its role in heterogeneity of response. High-throughput sequencing and imaging technologies can help recapitulate various aspects of the tumor ecosystem. Computational approaches provide an arsenal of tools to efficiently analyze, quantify and integrate multiple parameters of tumor immunity mined from these diverse but complementary high-throughput datasets. This chapter describes numerous such computational approaches in tumor immunology that leverage high-throughput data from diverse sources (genomic, transcriptomics, epigenomics and digitized histopathology images) to systematically interrogate tumor immunity in context of its microenvironment, and to identify mechanisms that confer resistance or sensitivity to cancer therapies, in particular immunotherapy.},
author = {Bhinder, Bhavneet and Elemento, Olivier},
doi = {10.1016/bs.mie.2020.01.001},
file = {:Users/texchi/Downloads/bhinder2020.pdf:pdf},
issn = {1557-7988 (Electronic)},
journal = {Methods in enzymology},
keywords = {Checkpoint blockingDeconvolutionDeep learningImmun},
language = {eng},
pages = {209--259},
pmid = {32178820},
title = {{Computational methods in tumor immunology.}},
volume = {636},
year = {2020}
}
@article{Steingrimsson2020,
abstract = {Deep learning is a class of machine learning algorithms that are popular for building risk prediction models. When observations are censored, the outcomes are only partially observed and standard deep learning algorithms cannot be directly applied. We develop a new class of deep learning algorithms for outcomes that are potentially censored. To account for censoring, the unobservable loss function used in the absence of censoring is replaced by a censoring unbiased transformation. The resulting class of algorithms can be used to estimate both survival probabilities and restricted mean survival. We show how the deep learning algorithms can be implemented by adapting software for uncensored data by using a form of response transformation. We provide comparisons of the proposed deep learning algorithms to existing risk prediction algorithms for predicting survival probabilities and restricted mean survival through both simulated datasets and analysis of data from breast cancer patients.},
annote = {History of deep survival analysis
time to event
right censoring ={\textgreater} Censoring unbiased loss functions12 (CULs) in deep learning: 
censoring unbiased deep learning (CUDL)

To overcome that challenge, Liao et al4 and Ranganath et al5proposed a deep learning algorithm where the loss function assumes a Weibull distributed failure time. Building on previous work,6 Katzman et al7 proposed a deep learning algorithm to estimate the functional form of the covariates in an underlying proportional hazard model using a loss function based on the partial likelihood of a proportional hazard model

={\textgreater} DeepSurv

===
KerasDeepLearning.R 
(Tensorflow)
from this article:
https://github.com/jonsteingrimsson/CensoringDL

the Keras interface to R. Keras is a high level application programming interface that incorporates various types of backend engines such as Tensorflow, CNTK, or Theano to train deep learning models.

==
DeepSurvK as well, using tensorflow},
author = {Steingrimsson, Jon Arni and Morrison, Samantha},
doi = {10.1002/sim.8542},
edition = {2020/04/13},
file = {:Users/texchi/Downloads/nihms-1586604.pdf:pdf},
issn = {1097-0258},
journal = {Statistics in medicine},
keywords = {CUDL,L2-loss,R,TFDeepSurv,censoring unbiased transformations,deep learning,doubly robust estimation,keras,machine learning,restricted mean survival,risk estimation,tensorflow},
language = {eng},
mendeley-tags = {CUDL,R,TFDeepSurv,deep learning,keras,tensorflow},
month = {jul},
number = {17},
pages = {2339--2349},
title = {{Deep learning for survival outcomes}},
url = {https://pubmed.ncbi.nlm.nih.gov/32281672 https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7334068/ https://github.com/jonsteingrimsson/CensoringDL},
volume = {39},
year = {2020}
}
@misc{rhee2018hybrid,
abstract = {Network biology has been successfully used to help reveal complex mechanisms of disease, especially cancer. On the other hand, network biology requires in-depth knowledge to construct disease-specific networks, but our current knowledge is very limited even with the recent advances in human cancer biology. Deep learning has shown a great potential to address the difficult situation like this. However, deep learning technologies conventionally use grid-like structured data, thus application of deep learning technologies to the classification of human disease subtypes is yet to be explored. Recently, graph based deep learning techniques have emerged, which becomes an opportunity to leverage analyses in network biology. In this paper, we proposed a hybrid model, which integrates two key components 1) graph convolution neural network (graph CNN) and 2) relation network (RN). We utilize graph CNN as a component to learn expression patterns of cooperative gene community, and RN as a component to learn associations between learned patterns. The proposed model is applied to the PAM50 breast cancer subtype classification task, the standard breast cancer subtype classification of clinical utility. In experiments of both subtype classification and patient survival analysis, our proposed method achieved significantly better performances than existing methods. We believe that this work is an important starting point to realize the upcoming personalized medicine.},
archivePrefix = {arXiv},
arxivId = {cs.CV/1711.05859},
author = {Rhee, Sungmin and Seo, Seokjun and Kim, Sun},
eprint = {1711.05859},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Rhee, Seo, Kim - 2018 - Hybrid Approach of Relation Network and Localized Graph Convolutional Filtering for Breast Cancer Subtype Classi.pdf:pdf},
keywords = {survival},
mendeley-tags = {survival},
primaryClass = {cs.CV},
title = {{Hybrid Approach of Relation Network and Localized Graph Convolutional Filtering for Breast Cancer Subtype Classification}},
year = {2018}
}
@article{Chai2020,
abstract = {New therapeutic targets for oral squamous cell carcinoma (OSCC) are urgently needed. We conducted genome-wide CRISPR-Cas9 screens in 21 OSCC cell lines, primarily derived from Asians, to identify genetic vulnerabilities that can be explored as therapeutic targets. We identify known and novel fitness genes and demonstrate that many previously identified OSCC-related cancer genes are non-essential and could have limited therapeutic value, while other fitness genes warrant further investigation for their potential as therapeutic targets. We validate a distinctive dependency on YAP1 and WWTR1 of the Hippo pathway, where the lost-of-fitness effect of one paralog can be compensated only in a subset of lines. We also discover that OSCCs with WWTR1 dependency signature are significantly associated with biomarkers of favourable response towards immunotherapy. In summary, we have delineated the genetic vulnerabilities of OSCC, enabling the prioritization of therapeutic targets for further exploration, including the targeting of YAP1 and WWTR1.},
author = {Chai, Annie Wai Yeeng and Yee, Pei San and Price, Stacey and Yee, Shi Mun and Lee, Hui Mei and Tiong, Vivian K.H. and Gon{\c{c}}alves, Emanuel and Behan, Fiona M. and Bateson, Jessica and Gilbert, James and Tan, Aik Choon and McDermott, Ultan and Garnett, Mathew J. and Cheong, Sok Ching},
doi = {10.7554/ELIFE.57761},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Chai et al. - 2020 - Genome-wide CRISPR screens of oral squamous cell carcinoma reveal fitness genes in the hippo pathway.pdf:pdf},
issn = {2050084X},
journal = {eLife},
keywords = {CRISPR screen,Fitness genes,HNSCC,Hippo pathway,Oral squamous cell carcinoma,Therapeutic targets,betel nut,hipo},
mendeley-tags = {HNSCC,betel nut,hipo},
month = {sep},
pages = {1--81},
pmid = {32990596},
publisher = {eLife Sciences Publications Ltd},
title = {{Genome-wide CRISPR screens of oral squamous cell carcinoma reveal fitness genes in the hippo pathway}},
volume = {9},
year = {2020}
}
@article{Cheerla2019,
abstract = {MOTIVATION: Estimating the future course of patients with cancer lesions is invaluable to physicians; however, current clinical methods fail to effectively use the vast amount of multimodal data that is available for cancer patients. To tackle this problem, we constructed a multimodal neural network-based model to predict the survival of patients for 20 different cancer types using clinical data, mRNA expression data, microRNA expression data and histopathology whole slide images (WSIs). We developed an unsupervised encoder to compress these four data modalities into a single feature vector for each patient, handling missing data through a resilient, multimodal dropout method. Encoding methods were tailored to each data type-using deep highway networks to extract features from clinical and genomic data, and convolutional neural networks to extract features from WSIs. RESULTS: We used pancancer data to train these feature encodings and predict single cancer and pancancer overall survival, achieving a C-index of 0.78 overall. This work shows that it is possible to build a pancancer model for prognosis that also predicts prognosis in single cancer sites. Furthermore, our model handles multiple data modalities, efficiently analyzes WSIs and represents patient multimodal data flexibly into an unsupervised, informative representation. We thus present a powerful automated tool to accurately determine prognosis, a key step towards personalized treatment for cancer patients. AVAILABILITY AND IMPLEMENTATION: https://github.com/gevaertlab/MultimodalPrognosis.},
annote = {https://github.com/gevaertlab/MultimodalPrognosis

deep highway networks to extract features from clinical and genomic data

convolutional neural networks to extract features from whole slide images},
author = {Cheerla, Anika and Gevaert, Olivier},
doi = {10.1093/bioinformatics/btz342},
issn = {1367-4811 (Electronic)},
journal = {Bioinformatics (Oxford, England)},
keywords = {Computer,Deep Learning,Genome,Humans,MultimodalPrognosis,Neoplasms,Neural Networks,genetics},
language = {eng},
mendeley-tags = {MultimodalPrognosis},
month = {jul},
number = {14},
pages = {i446--i454},
pmid = {31510656},
title = {{Deep learning with multimodal representation for pancancer prognosis prediction.}},
url = {https://academic.oup.com/bioinformatics/article/35/14/i446/5529139},
volume = {35},
year = {2019}
}
@article{Wulczyn2020,
abstract = {Providing prognostic information at the time of cancer diagnosis has important implications for treatment and monitoring. Although cancer staging, histopathological assessment, molecular features, and clinical variables can provide useful prognostic insights, improving risk stratification remains an active research area. We developed a deep learning system (DLS) to predict disease specific survival across 10 cancer types from The Cancer Genome Atlas (TCGA). We used a weakly-supervised approach without pixel-level annotations, and tested three different survival loss functions. The DLS was developed using 9,086 slides from 3,664 cases and evaluated using 3,009 slides from 1,216 cases. In multivariable Cox regression analysis of the combined cohort including all 10 cancers, the DLS was significantly associated with disease specific survival (hazard ratio of 1.58, 95{\%} CI 1.28–1.70, p{\textless}0.0001) after adjusting for cancer type, stage, age, and sex. In a per-cancer adjusted subanalysis, the DLS remained a significant predictor of survival in 5 of 10 cancer types. Compared to a baseline model including stage, age, and sex, the c-index of the model demonstrated an absolute 3.7{\%} improvement (95{\%} CI 1.0–6.5) in the combined cohort. Additionally, our models stratified patients within individual cancer stages, particularly stage II (p = 0.025) and stage III (p{\textless}0.001). By developing and evaluating prognostic models across multiple cancer types, this work represents one of the most comprehensive studies exploring the direct prediction of clinical outcomes using deep learning and histopathology images. Our analysis demonstrates the potential for this approach to provide significant prognostic information in multiple cancer types, and even within specific pathologic stages. However, given the relatively small number of cases and observed clinical events for a deep learning task of this type, we observed wide confidence intervals for model performance, thus highlighting that future work will benefit from larger datasets assembled for the purposes for survival modeling.},
author = {Wulczyn, Ellery and Steiner, David and Xu, Zhaoyang and Sadhwani, Apaar and Wang, Hongwu and Flament, Isabelle and Mermel, Craig and Chen, Cameron and Liu, Yun and Stumpe, Martin},
file = {:Users/texchi/Downloads/journal.pone.0233678.pdf:pdf},
journal = {PLOS ONE},
keywords = {deep learning,google,survival},
mendeley-tags = {deep learning,google,survival},
title = {{Deep learning-based survival prediction for multiple cancer types using histopathology images}},
url = {https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0233678},
year = {2020}
}
@article{Zhang2019,
abstract = {Logistic regression model is one of the most widely used modeling techniques in clinical medicine, owing to the widely available statistical packages for its implementation, and the ease of interpretation. However, logistic model training requires strict assumptions (such as additive and linearity) to be met and these assumptions may not hold true in real world. Thus, clinical investigators need to master some advanced model training methods that can predict more accurately. TensorFlow™ is a popular tool in training machine learning models such as supervised, unsupervised and reinforcement learning methods. Thus, it is important to learn TensorFlow™ in the era of big data. Since most clinical investigators are familiar with the logistic regression model, this article provides a step-by-step tutorial on how to train a logistic regression model in TensorFlow™, with the primary purpose to illustrate how the TensorFlow™ works. We first need to construct a graph with tensors and operations, then the graph is run in a session. Finally, we display the graph and summary statistics in the TensorBoard, which shows the changes of the accuracy and loss value across the training iterations.},
annote = {the installation of TensorFlow within R environment are available at https://tensorflow.rstudio.com/tensorflow/articles/installation.html.


* there is NO
Cox proportional hazards analyses;},
author = {Zhang, Zhongheng and Mo, Lei and Huang, Chen and Xu, Ping},
doi = {10.21037/atm.2019.09.125},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Zhang et al. - 2019 - Binary logistic regression modeling with TensorFlow™.pdf:pdf},
issn = {23055839},
journal = {Annals of Translational Medicine},
keywords = {Logistic regression,R,TensorFlow,gradient descent},
mendeley-tags = {Logistic regression,R,TensorFlow,gradient descent},
month = {oct},
number = {20},
pages = {591--591},
title = {{Binary logistic regression modeling with TensorFlow™}},
url = {http://atm.amegroups.com/article/view/30334/26367},
volume = {7},
year = {2019}
}
@inproceedings{Lee2018a,
abstract = {Survival analysis (time-to-event analysis) is widely used in economics and finance, engineering, medicine and many other areas. A fundamental problem is to understand the relationship between the covariates and the (distribution of) survival times (times-to-event). Much of the previous work has approached the problem by viewing the survival time as the first hitting time of a stochastic process, assuming a specific form for the underlying stochastic process, using available data to learn the relationship between the covariates and the parameters of the model, and then deducing the relationship between covariates and the distribution of first hitting times (the risk). However, previous models rely on strong parametric assumptions that are often violated. This paper proposes a very different approach to survival analysis, DeepHit, that uses a deep neural network to learn the distribution of survival times directly. DeepHit makes no assumptions about the underlying stochastic process and allows for the possibility that the relationship between covariates and risk(s) changes over time. Most importantly, DeepHit smoothly handles competing risks; i.e. settings in which there is more than one possible event of interest. Comparisons with previous models on the basis of real and synthetic datasets demonstrate that DeepHit achieves large and statistically significant performance improvements over previous state-of-the-art methods.},
annote = {https://humboldt-wi.github.io/blog/research/information{\_}systems{\_}1920/group2{\_}survivalanalysis/{\#}rsf

={\textgreater} a improvement by 
https://www.groundai.com/project/feature-selection-for-survival-analysis-with-competing-risks-using-deep-learning/1
https://arxiv.org/abs/1811.09317v4
DeeoHit+


software
https://bitbucket.org/mvdschaar/mlforhealthlabpub/src/f75f292e53e9485d742e865e55751f66f19dcf86/alg/deephit/
https://github.com/texchi2/DeepHit

Supplementary: http://medianetlab.ee.ucla.edu/papers/AAAI{\_}2018{\_}DeepHit{\_}Appendix},
author = {Lee, Changhee and Zame, William R. and Yoon, Jinsung and {Van Der Schaar}, Mihaela},
booktitle = {32nd AAAI Conference on Artificial Intelligence, AAAI 2018},
file = {:Users/texchi/Downloads/AAAI{\_}2018{\_}DeepHit.pdf:pdf},
isbn = {9781577358008},
keywords = {competing risks,deep learning,first-hitting-time analysis,neural networks,survi,survival analysis,tensorflow},
mendeley-tags = {deep learning,survi,tensorflow},
pages = {2314--2321},
title = {{DeepHit: A deep learning approach to survival analysis with competing risks}},
url = {https://www.aaai.org/ocs/index.php/AAAI/AAAI18/paper/view/16160 https://github.com/chl8856/DeepHit},
year = {2018}
}
@article{Chen2020a,
abstract = {Cancer diagnosis, prognosis, and therapeutic response predictions are based on morphological information from histology slides and molecular profiles from genomic data. However, most deep learning-based objective outcome prediction and grading paradigms are based on histology or genomics alone and do not make use of the complementary information in an intuitive manner. In this work, we propose Pathomic Fusion, an interpretable strategy for end-to-end multimodal fusion of histology image and genomic (mutations, CNV, RNASeq) features for survival outcome prediction. Our approach models pairwise feature interactions across modalities by taking the Kronecker product of unimodal feature representations, and controls the expressiveness of each representation via a gatingbased attention mechanism. Following supervised learning, we are able to interpret and saliently localize features across each modality, and understand how feature importance shifts when conditioning on multimodal input. We validate our approach using glioma and clear cell renal cell carcinoma datasets from the Cancer Genome Atlas (TCGA), which contains paired wholeslide image, genotype, and transcriptome data with ground truth survival and histologic grade labels. In a 15-fold cross-validation, our results demonstrate that the proposed multimodal fusion paradigm improves prognostic determinations from ground truth grading and molecular subtyping, as well as unimodal deep networks trained on histology and genomic data alone. The proposed method establishes insight and theory on how to train deep networks on multimodal biomedical data in an intuitive manner, which will be useful for other problems in medicine that seek to combine heterogeneous data streams for understanding diseases and predicting response and resistance to treatment. Code and trained models are made available at: https://github.com/mahmoodlab/PathomicFusion.},
annote = {https://github.com/mahmoodlab/PathomicFusion

Code Base Structure
The code base structure is explained below:
train{\_}cv.py: Cross-validation script for training unimodal and multimodal networks. This script will save evaluation metrics and predictions on the train + test split for each epoch on every split in checkpoints.
test{\_}cv.py: Script for testing unimodal and unimodal networks on only the test split.
train{\_}test.py: Contains the definitions for "train" and "test".
networks.py: Contains PyTorch model definitions for all unimodal and multimodal network.
fusion.py: Contains PyTorch model definitions for fusion.
data{\_}loaders.py: Contains the PyTorch DatasetLoader definition for loading multimodal data.
options.py: Contains all the options for the argparser.
make{\_}splits.py: Script for generating a pickle file that saves + aligns the path for multimodal data for cross-validation.
run{\_}cox{\_}baselines.py: Script for running Cox baselines.
utils.py: Contains definitions for collating, survival loss functions, data preprocessing, evaluation, figure plotting, etc...},
author = {Chen, Richard J and Lu, Ming Y and Wang, Jingwen and Williamson, Drew F K and Rodig, Scott J and Lindeman, Neal I and Mahmood, Faisal},
doi = {10.1109/TMI.2020.3021387},
file = {:Users/texchi/Downloads/10.1109@TMI.2020.3021387.pdf:pdf},
issn = {1558-254X (Electronic)},
journal = {IEEE transactions on medical imaging},
language = {eng},
month = {sep},
pmid = {32881682},
title = {{Pathomic Fusion: An Integrated Framework for Fusing Histopathology and Genomic Features for Cancer Diagnosis and Prognosis.}},
url = {https://pubmed.ncbi.nlm.nih.gov/32881682/},
volume = {PP},
year = {2020}
}
@article{Gerds2013,
abstract = {Given a predictive marker and a time-to-event response variable, the proportion of concordant pairs in a data set is called concordance index. A specifically useful marker is the risk predicted by a survival regression model. This article extends the existing methodology for applications where the length of the follow-up period depends on the predictor variables. A class of inverse probability of censoring weighted estimators is discussed in which the estimates rely on a working model for the conditional censoring distribution. The estimators are consistent for a truncated concordance index if the working model is correctly specified and if the probability of being uncensored at the truncation time is positive. In this framework, all kinds of prediction models can be assessed, and time trends in the discrimination ability of a model can be captured by varying the truncation time point. For illustration, we re-analyze a study on risk prediction for prostate cancer patients. The effects of misspecification of the censoring model are studied in simulated data. Copyright ? 2012 John Wiley {\&} Sons, Ltd.},
annote = {https://doi.org/10.1002/sim.5681},
author = {Gerds, Thomas A and Kattan, Michael W and Schumacher, Martin and Yu, Changhong},
doi = {https://doi.org/10.1002/sim.5681},
file = {:Users/texchi/Downloads/gerds2012.pdf:pdf},
issn = {0277-6715},
journal = {Statistics in Medicine},
keywords = {censored data,concordance index,deep learning,discrimination,inverse probability of censoring weighting,prediction models,survi,survival analysis},
mendeley-tags = {concordance index,deep learning,survi},
month = {jun},
number = {13},
pages = {2173--2184},
publisher = {John Wiley {\&} Sons, Ltd},
title = {{Estimating a time-dependent concordance index for survival prediction models with covariate dependent censoring}},
url = {https://doi.org/10.1002/sim.5681},
volume = {32},
year = {2013}
}
@misc{Moncada-Torres2020,
author = {Moncada-Torres, Arturo},
title = {{DeepSurvK}},
url = {https://deepsurvk.readthedocs.io/en/latest/},
year = {2020}
}
@misc{Iqbal2020,
abstract = {In this paper we propose the idea that Artificial intelligence (AI) is ushering in a new era of "Earlier Medicine," which is a predictive approach for disease prevention based on AI modeling and big data. The flourishing health care technological landscape is showing great potential-from diagnosis and prescription automation to the early detection of disease through efficient and cost-effective patient data screening tools that benefit from the predictive capabilities of AI. Monitoring the trajectories of both in- A nd outpatients has proven to be a task AI can perform to a reliable degree. Predictions can be a significant advantage to health care if they are accurate, prompt, and can be personalized and acted upon efficiently. This is where AI plays a crucial role in "Earlier Medicine" implementation.},
author = {Iqbal, Usman and Celi, Leo Anthony and Li, Yu Chuan Jack},
booktitle = {Journal of Medical Internet Research},
doi = {10.2196/17211},
issn = {14388871},
keywords = {Advanced care systems,Artificial intelligence,Digital health,Health care technology,Health information technology,Medical innovations,deep learning,eHealth},
mendeley-tags = {deep learning},
number = {8},
pages = {e17211},
pmid = {32780024},
title = {{How can artificial intelligence make medicine more preemptive?}},
url = {https://www.jmir.org/2020/8/e17211},
volume = {22},
year = {2020}
}
@misc{Kelly2019,
abstract = {Background: Artificial intelligence (AI) research in healthcare is accelerating rapidly, with potential applications being demonstrated across various domains of medicine. However, there are currently limited examples of such techniques being successfully deployed into clinical practice. This article explores the main challenges and limitations of AI in healthcare, and considers the steps required to translate these potentially transformative technologies from research to clinical practice. Main body: Key challenges for the translation of AI systems in healthcare include those intrinsic to the science of machine learning, logistical difficulties in implementation, and consideration of the barriers to adoption as well as of the necessary sociocultural or pathway changes. Robust peer-reviewed clinical evaluation as part of randomised controlled trials should be viewed as the gold standard for evidence generation, but conducting these in practice may not always be appropriate or feasible. Performance metrics should aim to capture real clinical applicability and be understandable to intended users. Regulation that balances the pace of innovation with the potential for harm, alongside thoughtful post-market surveillance, is required to ensure that patients are not exposed to dangerous interventions nor deprived of access to beneficial innovations. Mechanisms to enable direct comparisons of AI systems must be developed, including the use of independent, local and representative test sets. Developers of AI algorithms must be vigilant to potential dangers, including dataset shift, accidental fitting of confounders, unintended discriminatory bias, the challenges of generalisation to new populations, and the unintended negative consequences of new algorithms on health outcomes. Conclusion: The safe and timely translation of AI research into clinically validated and appropriately regulated systems that can benefit everyone is challenging. Robust clinical evaluation, using metrics that are intuitive to clinicians and ideally go beyond measures of technical accuracy to include quality of care and patient outcomes, is essential. Further work is required (1) to identify themes of algorithmic bias and unfairness while developing mitigations to address these, (2) to reduce brittleness and improve generalisability, and (3) to develop methods for improved interpretability of machine learning predictions. If these goals can be achieved, the benefits for patients are likely to be transformational.},
annote = {to develop methods for improved interpretability of machine learning predictions

Algorithmic interpretability is at an early stage but rapidly advancing
While AI approaches in medicine have yielded some impressive practical successes to date, their effectiveness is limited by their inability to ‘explain' their decision-making in an understandable way 

At present, a trade-off exists between performance and explainability. The best performing models (e.g. deep learning) are often the least explainable, whereas models with poorer performance (e.g. linear regression, decision trees) are the most explainable.

Explainable AI approaches are likely to facilitate faster adoption of AI systems into the clinical healthcare setting, and will help foster vital transparency and trust with their users.

所以第一線試用 IBM Watson for Oncology 已經失敗（不能只看結果）

survival analysis or biomarker discovery 則沒有那麼 critical need for Explainable AI.},
author = {Kelly, Christopher J. and Karthikesalingam, Alan and Suleyman, Mustafa and Corrado, Greg and King, Dominic},
booktitle = {BMC Medicine},
doi = {10.1186/s12916-019-1426-2},
issn = {17417015},
keywords = {Algorithms,Artificial intelligence,Evaluation,Machine learning,Regulation,Translation,deep learning,interpretability},
mendeley-tags = {deep learning,interpretability},
number = {1},
pages = {1--9},
pmid = {31665002},
title = {{Key challenges for delivering clinical impact with artificial intelligence}},
url = {https://bmcmedicine.biomedcentral.com/articles/10.1186/s12916-019-1426-2},
volume = {17},
year = {2019}
}
@software{Wagner2020,
abstract = {This model package contains the R codes for Windows of the image segmentation algorithm called U-net used in the article. As I don't own the rights to publish the original very high resolution images, this example was made with a simulated image of WorldView of the same resolution than the original data. The simulated objects to segment are red noisy blobs (with similar size as trees) on a noisy green background (see in the directory ("./data-raw/train"). This code version works with TensorFlow 2 and most of the code is based on an adaptation of the original codes for segmentation with Unet published on the RStudio AI Blog here: https://blogs.rstudio.com/ai/posts/2019-08-23-unet/. To run the model, it is assumed that you have a computer with GPU sufficient to run deep learning models (CUDA compute capacity {\textgreater}3.0), and Rstudio with the package keras already working (https://keras.rstudio.com/). The model validation accuracy starts to increase after {\~{}}10 to 20 epochs. After {\~{}}55 epochs, the validation accuracy is {\textgreater}0.95 and reach 0.9957{\%} at epoch 100. On my computer, one epoch runs in 7s. The R codes and the simulated data are distributed in a .zip of {\~{}}136.4 Mb. The RGB images are in the directory "./data-raw/train" and the labelled mask of the objects (0=background, 1=object) are in the directory "./data-raw/train{\_}masks". Pretrained weights for 100 epochs are found in the directory "./weights{\_}saved". The model was run with the following libraries: Python 3.7.6, RStudio Version 1.3.959, R version 4.0.2 (2020-06-22), R keras package version 2.3.0.0.9000, tensorflow version 2.2.0-rc4, tensorflow{\_}addons version 0.10.0 and a Nvidia GeForce RTX 2080 (driver 451.48, CUDA 10.1 and cuDNN version 7.6.5.32). When using this dataset, please cite the original article : https://doi.org/10.1371/journal.pone.0229448. To install all requirements to run TensorFlow-2 within Rstudio on Windows see the manual here : https://zenodo.org/record/3929710},
author = {Wagner, Fabien Hubert},
doi = {10.5281/zenodo.3926822},
keywords = {DeepSurvK,tensorflow},
mendeley-tags = {DeepSurvK,tensorflow},
month = {jan},
publisher = {Zenodo},
title = {{Model package from: Mapping Atlantic rainforest degradation and regeneration history with indicator species using convolutional network}},
url = {https://doi.org/10.5281/zenodo.3926822},
year = {2020}
}
@misc{kong2018graphembedded,
abstract = {Gene expression data represents a unique challenge in predictive model building, because of the small number of samples (n) compared to the huge amount of features (p). This "n{\textless}{\textless}p" property has hampered application of deep learning techniques for disease outcome classification. Sparse learning by incorporating external gene network information could be a potential solution to this issue. Still, the problem is very challenging because (1) there are tens of thousands of features and only hundreds of training samples, (2) the scale-free structure of the gene network is unfriendly to the setup of convolutional neural networks. To address these issues and build a robust classification model, we propose the Graph-Embedded Deep Feedforward Networks (GEDFN), to integrate external relational information of features into the deep neural network architecture. The method is able to achieve sparse connection between network layers to prevent overfitting. To validate the method's capability, we conducted both simulation experiments and a real data analysis using a breast cancer RNA-seq dataset from The Cancer Genome Atlas (TCGA). The resulting high classification accuracy and easily interpretable feature selection results suggest the method is a useful addition to the current classification models and feature selection procedures. The method is available at https://github.com/yunchuankong/GEDFN},
annote = {https://github.com/yunchuankong/GEDFN
https://github.com/yunchuankong/NetworkNeuralNetwork

=

supplement
https://oup.silverchair-cdn.com/oup/backfile/Content{\_}public/Journal/bioinformatics/34/21/10.1093{\_}bioinformatics{\_}bty429/1/bty429{\_}supporting{\_}file.pdf?Expires=1608280474{\&}Signature=EnAcJsOIcH4wCD25lkNRRjG7{\~{}}laTUpomvID7C2EIYEMoI3qFdcpbGCHOAwtg{\~{}}ZewJ7iRgGI{\~{}}b4d-Xbdoq7HV2iIei4-7VFgsQkCRxHTsT{\~{}}ihIkn5kdrVIXqT2X8CU2o2Fuoak0C4{\~{}}2PLmR9gUg1CCcE8t0MbzQZL4vx-3kds0TajHcZAQhqhNyHhceNr50pAUmhrUwijm9y6Gdvv3qQCxLXRdZI-VhDmbiMFR5-ZDaSUB8Cfer4i{\~{}}3VUAl7uHCxB9UUjXfCC4JSeinqZaEdDefoGNpIPcrbvvQKyHatELNfnzuNA87gxtBu2AUkLyJHfSH6Hu9{\~{}}EByhmPPst99jrZg{\_}{\_}{\&}Key-Pair-Id=APKAIE5G5CRDK6RD3PGA},
archivePrefix = {arXiv},
arxivId = {stat.ML/1801.06202},
author = {Kong, Yunchuan and Yu, Tianwei},
doi = {10.1093/bioinformatics/bty429},
eprint = {1801.06202},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Kong, Yu - 2018 - A graph-embedded deep feedforward network for disease outcome classification and feature selection using gene expressi.pdf:pdf;:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Kong, Yu - 2018 - A graph-embedded deep feedforward network for disease outcome classification and feature selection using gene express.docx:docx},
keywords = {GEDFN,Graph,RNA-seq,TCGA,Tensorflow,deep learning},
mendeley-tags = {GEDFN,Graph,RNA-seq,TCGA,Tensorflow,deep learning},
primaryClass = {stat.ML},
title = {{A graph-embedded deep feedforward network for disease outcome classification and feature selection using gene expression data}},
url = {https://academic.oup.com/bioinformatics/article/34/21/3727/5021680 https://oup.silverchair-cdn.com/oup/backfile/Content{\_}public/Journal/bioinformatics/34/21/10.1093{\_}bioinformatics{\_}bty429/1/bty429{\_}supporting{\_}file.pdf?Expires=1608280474{\&}Signature=EnAcJsOIcH4},
year = {2018}
}
@article{Rietschel2019,
abstract = {Deep learning models for survival analysis have gained significant attention in the literature, but they suffer from severe performance deficits when the dataset contains many irrelevant features. We give empirical evidence for this problem in real-world medical settings using the state-of-the-art model DeepHit. Furthermore, we develop methods to improve the deep learning model through novel approaches to feature selection in survival analysis. We propose filter methods for hard feature selection and a neural network architecture that weights features for soft feature selection. Our experiments on two real-world medical datasets demonstrate that substantial performance improvements against the original models are achievable.},
annote = {https://github.com/texchi2/deephitplus},
archivePrefix = {arXiv},
arxivId = {1811.09317v4},
author = {Rietschel, Carl and Yoon, Jinsung and van der Schaar, Mihaela},
eprint = {1811.09317v4},
file = {:Users/texchi/Downloads/1811.09317v4.pdf:pdf},
journal = {arXiv},
keywords = {DeepHit},
mendeley-tags = {DeepHit},
title = {{Feature Selection for Survival Analysis with Competing Risks using Deep Learning}},
url = {https://arxiv.org/abs/1811.09317v4},
year = {2019}
}
@article{Lee2020a,
abstract = {Currently available risk prediction methods are limited in their ability to deal with complex, heterogeneous, and longitudinal data such as that available in primary care records, or in their ability to deal with multiple competing risks. This paper develops a novel deep learning approach that is able to successfully address current limitations of standard statistical approaches such as landmarking and joint modeling. Our approach, which we call Dynamic-DeepHit, flexibly incorporates the available longitudinal data comprising various repeated measurements (rather than only the last available measurements) in order to issue dynamically updated survival predictions for one or multiple competing risk(s). Dynamic-DeepHit learns the time-to-event distributions without the need to make any assumptions about the underlying stochastic models for the longitudinal and the time-to-event processes. Thus, unlike existing works in statistics, our method is able to learn data-driven associations between the longitudinal data and the various associated risks without underlying model specifications. We demonstrate the power of our approach by applying it to a real-world longitudinal dataset from the U.K. Cystic Fibrosis Registry, which includes a heterogeneous cohort of 5883 adult patients with annual follow-ups between 2009 to 2015. The results show that Dynamic-DeepHit provides a drastic improvement in discriminating individual risks of different forms of failures due to cystic fibrosis. Furthermore, our analysis utilizes post-processing statistics that provide clinical insight by measuring the influence of each covariate on risk predictions and the temporal importance of longitudinal measurements, thereby enabling us to identify covariates that are influential for different competing risks.},
annote = {xx http://www.vanderschaar-lab.com/NewWebsite/CF{\_}Changhee{\_}TBME{\_}demonstrator.html
https://bitbucket.org/mvdschaar/mlforhealthlabpub/src/master/README.md


Machine learning, however, can accurately model survival of patients in such a highly heterogeneous cohort, while treating CVD and cancer as competing risks. We have demonstrated this our lab's own survival models for competing risks, DeepHit and Dynamic-DeepHit, which offer personalized actionable prognoses that clinicians can use to design personalized treatment plans. Experiments on real-world data have demonstrated that our models outperform state-of-the-art survival models.},
author = {Lee, Changhee and Yoon, Jinsung and van der Schaar, Mihaela},
doi = {10.1109/TBME.2019.2909027},
file = {:Users/texchi/Downloads/lee2019.pdf:pdf},
issn = {1558-2531 (Electronic)},
journal = {IEEE transactions on bio-medical engineering},
keywords = {DeepHit,censoring,deep learning,survival,time-to-event},
language = {eng},
mendeley-tags = {DeepHit,censoring,deep learning,survival,time-to-event},
month = {jan},
number = {1},
pages = {122--133},
pmid = {30951460},
title = {{Dynamic-DeepHit: A Deep Learning Approach for Dynamic Survival Analysis With Competing Risks Based on Longitudinal Data.}},
volume = {67},
year = {2020}
}
@misc{Dalagnol2020,
author = {Dalagnol, Ricardo and Wagner, Fabien},
doi = {10.5281/zenodo.3929710},
file = {:Users/texchi/Downloads/Install{\_}guide{\_}Tensorflow{\_}Keras{\_}in{\_}Rstudio.pdf:pdf},
month = {jul},
publisher = {Zenodo},
title = {{Tensorflow and Keras installation steps for Deep Learning applications in Rstudio}},
url = {https://doi.org/10.5281/zenodo.3929710},
urldate = {2020-11-07},
year = {2020}
}
@article{Katzman2018,
abstract = {Medical practitioners use survival models to explore and understand the relationships between patients' covariates (e.g. clinical and genetic features) and the effectiveness of various treatment options. Standard survival models like the linear Cox proportional hazards model require extensive feature engineering or prior medical knowledge to model treatment interaction at an individual level. While nonlinear survival methods, such as neural networks and survival forests, can inherently model these high-level interaction terms, they have yet to be shown as effective treatment recommender systems.},
annote = {DeepSurv implements a deep learning generalization of the Cox proportional hazards model using Theano and Lasagne.
DeepSurv has an advantage over traditional Cox regression because it does not require an a priori selection of covariates, but learns them adaptively.
DeepSurv can be used in numerous survival analysis applications. One medical application is provided: recommend{\_}treatment, which provides treatment recommendations for a set of patient observations.


... DeepSurvK

DeepSurv is a Cox Proportional Hazards deep neural network used for modeling interactions between a patient's covariates and treatment effectiveness. It was originally proposed by Katzman et. al (2018) and implemented in Theano (using Lasagne).
Unfortunately, Theano is no longer supported. There have been some attempts in recreating DeepSurv in other DL platforms, such as czifan's DeepSurv.pytorch. However, given its popularity and ease of use, I think TensorFlow 2's Keras is a great option for this task.
mexchy1000 created DeepSurv{\_}Keras. However, it is a very raw prototype: it is not properly documented nor validated. Moreover, it is not being actively supported anymore. Therefore, I used it as a rough starting point for the development of DeepSurvK.

https://deepsurvk.readthedocs.io/en/latest/},
author = {Katzman, Jared L and Shaham, Uri and Cloninger, Alexander and Bates, Jonathan and Jiang, Tingting and Kluger, Yuval},
doi = {10.1186/s12874-018-0482-1},
file = {:Users/texchi/Downloads/s12874-018-0482-1.pdf:pdf},
issn = {1471-2288},
journal = {BMC Medical Research Methodology},
keywords = {deep learning,deepSurv},
mendeley-tags = {deep learning,deepSurv},
number = {1},
pages = {24},
title = {{DeepSurv: personalized treatment recommender system using a Cox proportional hazards deep neural network}},
url = {https://doi.org/10.1186/s12874-018-0482-1},
volume = {18},
year = {2018}
}
@article{Sun2019,
abstract = {Breast cancer is a highly aggressive type of cancer with very low median survival. Accurate prognosis prediction of breast cancer can spare a significant number of patients from receiving unnecessary adjuvant systemic treatment and its related expensive medical costs. Previous work relies mostly on selected gene expression data to create a predictive model. The emergence of deep learning methods and multi-dimensional data offers opportunities for more comprehensive analysis of the molecular characteristics of breast cancer and therefore can improve diagnosis, treatment, and prevention. In this study, we propose a Multimodal Deep Neural Network by integrating Multi-dimensional Data (MDNNMD) for the prognosis prediction of breast cancer. The novelty of the method lies in the design of our method's architecture and the fusion of multi-dimensional data. The comprehensive performance evaluation results show that the proposed method achieves a better performance than the prediction methods with single-dimensional data and other existing approaches. The source code implemented by TensorFlow 1.0 deep learning library can be downloaded from the Github: https://github.com/USTC-HIlab/MDNNMD.},
author = {Sun, D and Wang, M and Li, A},
doi = {10.1109/TCBB.2018.2806438},
file = {:Users/texchi/Downloads/sun2018.pdf:pdf},
issn = {1557-9964 VO - 16},
journal = {IEEE/ACM Transactions on Computational Biology and Bioinformatics},
keywords = {Breast cancer,Breast cancer prognosis prediction,Feature extraction,Gene expression,MDNNMD,Machine learning,Neural networks,Prognostics and health management,TensorFlow 1.0 deep learning library,bioinformatics,cancer,deep learning,feature extraction,gene expression data,genetics,human breast cancer prognosis prediction,learning (artificial intelligence),molecular biophysics,molecular characteristics,multi-dimensional data,multimodal deep neural network,multimodal deep neural network by integrating mult,neural nets,patient treatment,predictive model,single-dimensional data,source code,survival},
mendeley-tags = {MDNNMD,deep learning,survival},
number = {3},
pages = {841--850},
title = {{A Multimodal Deep Neural Network for Human Breast Cancer Prognosis Prediction by Integrating Multi-Dimensional Data}},
volume = {16},
year = {2019}
}
@article{Kim2019,
abstract = {The Cox proportional hazards model commonly used to evaluate prognostic variables in survival of cancer patients may be too simplistic to properly predict a cancer patient's outcome since it assumes that the outcome is a linear combination of covariates. In this retrospective study including 255 patients suitable for analysis who underwent surgical treatment in our department from 2000 to 2017, we applied a deep learning-based survival prediction method in oral squamous cell carcinoma (SCC) patients and validated its performance. Survival prediction using DeepSurv, a deep learning based-survival prediction algorithm, was compared with random survival forest (RSF) and the Cox proportional hazard model (CPH). DeepSurv showed the best performance among the three models, the c-index of the training and testing sets reaching 0.810 and 0.781, respectively, followed by RSF (0.770/0.764), and CPH (0.756/0.694). The performance of DeepSurv steadily improved with added features. Thus, deep learning-based survival prediction may improve prediction accuracy and guide clinicians both in choosing treatment options for better survival and in avoiding unnecessary treatments.},
annote = {Deep learning-based survival analysis
DeepSurv by Katzman et al. was implemented as an open-source Python module (https://github.com/jaredleekatzman/DeepSurv)16. 
DeepSurv is a multi-layer feed forward network, of which the output is a negative log partial likelihood, parameterized by the weights of the network. It is implemented in Theano with the Python package Lasagne. It also includes hyper-parameter optimization search. The source code is available at the above URL.

= concordance index
Harrell's c-index is known to be the most accurate and suitable method for estimating prediction error15. The c-index is used most commonly as a metric for survival prediction and reflects a measure of how well a model predicts the ordering of patients' death times. A c = 0.5 is the average of a random model, and c = 1 refers to a perfect match of death time ranking
==

comparing 3 algorisms:

Deep learning based-survival model, random survival forest (RSF), and CPH model were built and their performance compared with one another using Harrell's c-index.},
author = {Kim, Dong Wook and Lee, Sanghoon and Kwon, Sunmo and Nam, Woong and Cha, In-Ho and Kim, Hyung Jun},
doi = {10.1038/s41598-019-43372-7},
file = {:Users/texchi/Downloads/s41598-019-43372-7.pdf:pdf},
issn = {2045-2322},
journal = {Scientific Reports},
keywords = {Cox,HNSCC,deep learning,deepSurv},
mendeley-tags = {Cox,HNSCC,deep learning,deepSurv},
number = {1},
pages = {6994},
title = {{Deep learning-based survival prediction of oral cancer patients}},
url = {https://doi.org/10.1038/s41598-019-43372-7},
volume = {9},
year = {2019}
}
@article{Jeong2020,
abstract = {Background: Artificial Intelligence (AI) frameworks have emerged as a novel approach in medicine. However, information regarding its applicability and effectiveness in a clinical prognostic factor setting remains unclear. Methods: The AI framework was derived from a pooled dataset of intrahepatic cholangiocarcinoma (ICC) patients from three clinical centers (n = 1,421) by applying the TensorFlow deep learning algorithm to Cox-indicated pathologic (four), serologic (six), and etiologic (two) factors; this algorithm was validated using a dataset of ICC patients from an independent clinical center (n = 234). The model was compared to the commonly used staging system (American Joint Committee on Cancer; AJCC) and methodology (Cox regression) by evaluating the brier score (BS), integrated discrimination improvement (IDI), net reclassification improvement (NRI), and area under curve (AUC) values. Results: The framework (BS, 0.17; AUC, 0.78) was found to be more accurate than the AJCC stage (BS, 0.48; AUC, 0.60; IDI, 0.29; NRI, 11.85; P {\textless} 0.001) and the Cox model (BS, 0.49; AUC, 0.70; IDI, 0.46; NRI, 46.11; P {\textless} 0.001). Furthermore, hazard ratios greater than three were identified in both overall survival (HR; 3.190; 95{\%} confidence interval [CI], 2.150–4.733; P {\textless} 0.001) and disease-free survival (HR, 3.559; 95{\%} CI, 2.500–5.067; P {\textless} 0.001) between latent risk and stable groups in validation. In addition, the latent risk subgroup was found to be significantly benefited from adjuvant treatment (HR, 0.459; 95{\%} CI, 0.360–0.586; P {\textless} 0.001). Conclusions: The AI framework seems promising in the prognostic estimation and stratification of susceptible individuals for adjuvant treatment in patients with ICC after resection. Future prospective validations are needed for the framework to be applied in clinical practice.},
author = {Jeong, Seogsong and Ge, Yang and Chen, Jing and Gao, Qiang and Luo, Guijuan and Zheng, Bo and Sha, Meng and Shen, Feng and Cheng, Qingbao and Sui, Chengjun and Liu, Jingfeng and Wang, Hongyang and Xia, Qiang and Chen, Lei},
doi = {10.3389/fonc.2020.00143},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Jeong et al. - 2020 - Latent Risk Intrahepatic Cholangiocarcinoma Susceptible to Adjuvant Treatment After Resection A Clinical Deep Lear.pdf:pdf},
issn = {2234943X},
journal = {Frontiers in Oncology},
keywords = {Cox,TensorFlow,artificial intelligence,biliary malignancy,deep learning,prediction model,primary liver cancer,prognostic factor,survival analysis},
mendeley-tags = {Cox,TensorFlow,deep learning,survival analysis},
month = {feb},
publisher = {Frontiers Media S.A.},
title = {{Latent Risk Intrahepatic Cholangiocarcinoma Susceptible to Adjuvant Treatment After Resection: A Clinical Deep Learning Approach}},
volume = {10},
year = {2020}
}
@misc{Utkin2020,
abstract = {A new modification of the explanation method SurvLIME called SurvLIME-Inf for explaining machine learning survival models is proposed. The basic idea behind SurvLIME as well as SurvLIME-Inf is to apply the Cox proportional hazards model to approximate the black-box survival model at the local area around a test example. The Cox model is used due to the linear relationship of covariates. In contrast to SurvLIME, the proposed modification uses L∞-norm for defining distances between approximating and approximated cumulative hazard functions. This leads to a simple linear programming problem for determining important features and for explaining the black-box model prediction. Moreover, SurvLIME-Inf outperforms SurvLIME when the training set is very small. Numerical experiments with synthetic and real datasets demonstrate the SurvLIME-Inf efficiency.},
annote = {https://www.arxiv-vanity.com/papers/1602.04938/Local Interpretable Model-agnostic Explanations (LIME):
from},
archivePrefix = {arXiv},
arxivId = {cs.LG/2005.02387},
author = {Utkin, Lev V and Kovalev, Maxim S and Kasimov, Ernest M},
booktitle = {arXivLabs},
eprint = {2005.02387},
file = {:Users/texchi/Library/Application Support/Mendeley Desktop/Downloaded/Utkin, Kovalev, Kasimov - 2020 - SurvLIME-Inf A simplified modification of SurvLIME for explanation of machine learning survival models.pdf:pdf},
keywords = {Cox proportional hazards model,GNN,LIME,SurvLIME,censoring,survival SurvLIME-Inf},
mendeley-tags = {Cox proportional hazards model,GNN,LIME,SurvLIME,censoring,survival SurvLIME-Inf},
primaryClass = {cs.LG},
title = {{SurvLIME-Inf: A simplified modification of SurvLIME for explanation of machine learning survival models}},
url = {https://arxiv.org/abs/2005.02387v1 https://www.arxiv-vanity.com/papers/2005.02387/},
urldate = {2020-11-30},
year = {2020}
}
@article{Tranchevent2019,
abstract = {Background The availability of high-throughput omics datasets from large patient cohorts has allowed the development of methods that aim at predicting patient clinical outcomes, such as survival and disease recurrence. Such methods are also important to better understand the biological mechanisms underlying disease etiology and development, as well as treatment responses. Recently, different predictive models, relying on distinct algorithms (including Support Vector Machines and Random Forests) have been investigated. In this context, deep learning strategies are of special interest due to their demonstrated superior performance over a wide range of problems and datasets. One of the main challenges of such strategies is the “small n large p” problem. Indeed, omics datasets typically consist of small numbers of samples and large numbers of features relative to typical deep learning datasets. Neural networks usually tackle this problem through feature selection or by including additional constraints during the learning process. Methods We propose to tackle this problem with a novel strategy that relies on a graph-based method for feature extraction, coupled with a deep neural network for clinical outcome prediction. The omics data are first represented as graphs whose nodes represent patients, and edges represent correlations between the patients' omics profiles. Topological features, such as centralities, are then extracted from these graphs for every node. Lastly, these features are used as input to train and test various classifiers. Results We apply this strategy to four neuroblastoma datasets and observe that models based on neural networks are more accurate than state of the art models (DNN: 85{\%}-87{\%}, SVM/RF: 75{\%}-82{\%}). We explore how different parameters and configurations are selected in order to overcome the effects of the small data problem as well as the curse of dimensionality. Conclusions Our results indicate that the deep neural networks capture complex features in the data that help predicting patient clinical outcomes.},
annote = {Implementation
The data processing was performed in python (using packages numpy and pandas). The graph inference and topological analyses were performed in python and C++ (using packages networkx, scipy, igraph, graph-tool and SNFtool). The SVM and RF classifiers were built in R (with packages randomForest and e1071). The DNN classifiers were built in python (with TensorFlow) using the DNNClassifier estimator. Training was performed using only CPU cores. GEDFN was run in Python using the implementation provided by the authors. Figures and statistical tests were prepared in R.


This article has been published as part of BMC Medical Genomics, Volume 12 Supplement 8, 2019: 18th International Conference on Bioinformatics. The full contents of the supplement are available at https://bmcmedgenomics.biomedcentral.com/articles/supplements/volume-12-supplement-8.},
author = {Tranchevent, L{\'{e}}on-charles and Azuaje, Francisco and Rajapakse, Jagath C},
doi = {10.1186/s12920-019-0628-y},
file = {:Users/texchi/Downloads/Tranchevent2019{\_}Article{\_}ADeepNeuralNetworkApproachToPr.pdf:pdf},
issn = {1755-8794},
journal = {BMC Medical Genomics},
keywords = {C++,Clinical outcome prediction,DNN,Deep learning,Deep neural network,Disease prediction,Graph topology,Machine learning,Network-based methods,and,asjagath,bioinformatics research center,clinical outcome prediction,correspondence,deep learning,deep neural network,disease prediction,edu,graph topology,machine learning,network-based methods,ntu,school of computer science,sg,survival},
mendeley-tags = {C++,DNN,deep learning,survival},
pages = {1--11},
publisher = {BMC Medical Genomics},
title = {{A deep neural network approach to predicting clinical outcomes of neuroblastoma patients}},
url = {http://dx.doi.org/10.1186/s12920-019-0628-y},
volume = {12},
year = {2019}
}
@article{Rampasek2016,
author = {Rampasek, Ladislav and Goldenberg, Anna},
doi = {10.1016/j.cels.2016.01.009},
file = {:Users/texchi/Downloads/PIIS2405471216000107.pdf:pdf},
issn = {2405-4712},
journal = {Cell Systems},
keywords = {Tensorflow,deep learning},
mendeley-tags = {Tensorflow,deep learning},
number = {1},
pages = {12--14},
publisher = {Elsevier Inc.},
title = {{TensorFlow : Biology ' s Gateway to Deep Learning ?}},
url = {http://dx.doi.org/10.1016/j.cels.2016.01.009},
volume = {2},
year = {2016}
}
@article{Fortelny2020,
abstract = {Deep learning has emerged as a versatile approach for predicting complex biological phenomena. However, its utility for biological discovery has so far been limited, given that generic deep neural networks provide little insight into the biological mechanisms that underlie a successful prediction. Here we demonstrate deep learning on biological networks, where every node has a molecular equivalent, such as a protein or gene, and every edge has a mechanistic interpretation, such as a regulatory interaction along a signaling pathway.},
annote = {Availability of data and materials
All datasets are openly available from public databases. The TCR dataset [49] was downloaded from GEO (GSE137554). The HCA dataset [50] was downloaded from the “Census of Immune Cells” that is part of the Human Cell Atlas (https://preview.data.humancellatlas.org/), as of 31 July 2018. The LCH dataset [51] was downloaded from GEO (GSE133704). The AML dataset [52] was downloaded from GEO (GSE116256). The glioblastoma dataset [53] was downloaded from GEO (GSE131928). The source code to train and analyze KPNNs (in Python and R) is available under the GNU General Public License v3.0 as a GitHub repository [125] and in archived form in Zenodo [126].

==
https://zenodo.org/record/3697744{\#}.X8Ouey0RoUQ
https://github.com/epigen/KPNN
https://github.com/hussius/deeplearning-biology},
author = {Fortelny, Nikolaus and Bock, Christoph},
doi = {10.1186/s13059-020-02100-5},
file = {:Users/texchi/Downloads/s13059-020-02100-5.pdf:pdf},
issn = {1474-760X},
journal = {Genome Biology},
keywords = {GCN,Interpretable deep learning,KPNNs,acyclic graph,single-cell RNA-seq,tensorflow},
mendeley-tags = {GCN,Interpretable deep learning,KPNNs,acyclic graph,single-cell RNA-seq,tensorflow},
number = {1},
pages = {190},
title = {{Knowledge-primed neural networks enable biologically interpretable deep learning on single-cell sequencing data}},
url = {https://doi.org/10.1186/s13059-020-02100-5},
volume = {21},
year = {2020}
}
